


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import root_mean_squared_error
from sklearn.metrics import mean_absolute_percentage_error

# my imports, has the cleaning + visualization libraries, as well as some models and some metrics


df = pd.read_csv('data/universities.csv') # reading dataset





pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
# having no setting for max rows and columns to look at the data with ease


df.info()
# looking at everything using info


sub = df.dropna()
# dropping the Null values and storing that in the variable


sub.to_csv('data/cleaned_universities.csv')
# making a new csv with the variable from earlier





data = pd.read_csv('data/cleaned_universities.csv')
# reading in the new dataframe from the previous cell


data.head()





data.info()
# showing the info of the new csv


sns.set_style('darkgrid')


plt.figure(figsize= (7, 11))
sns.heatmap(data.corr(numeric_only= True)[['in-state tuition']].sort_values(by = 'in-state tuition', ascending = False), 
           annot = True, 
           vmin = -1, 
           vmax = 1, 
           cmap = 'coolwarm')
plt.title('Correlation for Modeling')
plt.xlabel('Corrs of In-State Tuition')
plt.ylabel('Features')
plt.savefig('Model_Visuals/correlation_of_tuition_and_features.png')
# making a heatmap of the new csv to showcase correlations so that I can make good predictions


sns.scatterplot(data, x = 'in-state tuition', y = 'board',hue = 'Public (1)/ Private (2)')
plt.title('In-State Tuition by Board Cost')
plt.xlabel('In-State Tuition (in USD)')
plt.ylabel('Board Cost (in USD)')
plt.savefig('Model_Visuals/in_state_tuition_by_board.png')
# scatter plot of in state tuition and board cost, with two groups public or private


sns.scatterplot(data, x = 'in-state tuition', y = 'stud./fac. ratio',hue = 'Public (1)/ Private (2)')
plt.title('In-State Tuition by Student Faculty Ratio')
plt.xlabel('In-State Tuition (in USD)')
plt.ylabel('Student Faculty Ratio')
plt.savefig('Model_Visuals/in_state_tuition_by_student_faculty_ratio.png')
# scatter plot of in state tuition and student faculty ratio, with two groups, public or private





X = data[['Public (1)/ Private (2)','board','Graduation rate','% new stud. from top 10%','% new stud. from top 25%','room','stud./fac. ratio']] 
# selected these features as they correlated strongly with the in state tuition with out being heavily related/weird for a web app (like out-of-state tuition)
y = data['in-state tuition']
# i just wanted to predict the instate tuition





scores = []

for i in range(10, 26, 1):
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = i/100)
    lr = LinearRegression()
    lr.fit(X_train, y_train)
    train_score = lr.score(X_train, y_train)
    test_score = lr.score(X_test, y_test)

    scores.append({'test_size': i, 'train_score': train_score, 'test_score': test_score})

df_scores = pd.DataFrame(scores)

# creating a for loop to look at all of the scores for different test sizes at once


df_scores
# test size 16 seems to be the best


X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.16)

lr = LinearRegression()

lr.fit(X_train, y_train)


lr.score(X_test, y_test)


y_pred = lr.predict(X_test)


lr_rmse =root_mean_squared_error(y_test, y_pred)
lr_rmse


baseline_preds = np.full_like(y_test, y_test.mean())
basline_rmse = root_mean_squared_error(y_test, baseline_preds)
basline_rmse


mean_absolute_percentage_error(y_test, y_pred)

# seems to be my second best model, thoiugh random forest seems to be marginally better at certain things (like mean absolute ercentage error)





scores = []

for i in range(10, 26, 1):
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = i/100)
    dtr = DecisionTreeRegressor(random_state = 42)
    dtr.fit(X_train, y_train)
    train_score = dtr.score(X_train, y_train)
    test_score = dtr.score(X_test, y_test)
    
    scores.append({'test_size': i, 'train_score': train_score, 'test_score': test_score})

df_scores = pd.DataFrame(scores)

# creating a for loop to look at all of the scores for different test sizes at once


df_scores
# test size of 16 percent seems to be the best for this one


X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.16)

dtr = DecisionTreeRegressor(random_state= 42)

dtr.fit(X_train, y_train)


dtr.score(X_test, y_test)


y_pred = dtr.predict(X_test)


dtr_rmse =root_mean_squared_error(y_test, y_pred)
dtr_rmse


baseline_preds = np.full_like(y_test, y_test.mean())
basline_rmse = root_mean_squared_error(y_test, baseline_preds)
basline_rmse


mean_absolute_percentage_error(y_test, y_pred)

# probably my worst model, but I think knn is a close second (horribl mape score on knn)





scores = []

for i in range(10, 26, 1):
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = i/100)
    rfr = RandomForestRegressor(random_state= 42)
    rfr.fit(X_train, y_train)
    train_score = rfr.score(X_train, y_train)
    test_score = rfr.score(X_test, y_test)
    
    scores.append({'test_size': i, 'train_score': train_score, 'test_score': test_score})

df_scores = pd.DataFrame(scores)


df_scores
# tyest size 18 percent


X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.18)

rfr = RandomForestRegressor(random_state= 42)

rfr.fit(X_train, y_train)


rfr.score(X_test, y_test)


y_pred = rfr.predict(X_test)


rfr_rmse =root_mean_squared_error(y_test, y_pred)
rfr_rmse


baseline_preds = np.full_like(y_test, y_test.mean())
basline_rmse = root_mean_squared_error(y_test, baseline_preds)
basline_rmse


mean_absolute_percentage_error(y_test, y_pred)

# the model I chose to pickler, I chose it because its test score is great and its mean absolute percentage error is the best. its rmse seems to be slightly worse than the linrear regression model but only slightly





import pickle


rfr_pkl = ''


with open('rfr_pkl', 'wb') as file:
    model = pickle.dump(rfr, file)


with open('rfr_pkl', 'rb') as file:
    model = pickle.load(file)








from sklearn.preprocessing import StandardScaler
# importing standard scaler cause I forgot to


X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=16)


sc = StandardScaler()
X_train_sc = sc.fit_transform(X_train)
X_test_sc = sc.transform(X_test)
# scaling my X_train and X_test


scores = []

for k in range(3, 32, 2):
    knn = KNeighborsRegressor(n_neighbors = k)
    knn.fit(X_train_sc, y_train)
    train_score = knn.score(X_train_sc, y_train)
    test_score = knn.score(X_test_sc, y_test)

    scores.append({'k': k, 'train_score': train_score, 'test_score': test_score})

df_scores = pd.DataFrame(scores)


df_scores
# k of 3 + test size of 16 cause it gave a great score


knn.score(X_test_sc, y_test)


y_pred = knn.predict(X_test_sc)


knn_rmse =root_mean_squared_error(y_test, y_pred)
knn_rmse


baseline_preds = np.full_like(y_test, y_test.mean())
basline_rmse = root_mean_squared_error(y_test, baseline_preds)
basline_rmse


mean_absolute_percentage_error(y_test, y_pred)

# second worse model, great r squared and rmse, but horrible mape, probably cause knn makes estimates on how close it is to other points
